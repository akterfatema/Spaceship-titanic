# -*- coding: utf-8 -*-
"""spaceship_titanic_kaggle.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14-vpa1oCl2eMpLj5SXI7HOYqYeVvHlYp
"""

from google.colab import drive

drive.mount('/content/drive')

#creating dataframes
import pandas as pd
train_df = pd.read_csv('/content/drive/MyDrive/CSE366/train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/CSE366/test.csv')

train_df.info()

test_df.info()

"""# Data Cleaning and Preprocessing"""

# dropping unnecessary columns
train_df.drop(['PassengerId', 'Name', 'Cabin'], axis = 1, inplace = True)
test_df.drop(['Name', 'Cabin'], axis = 1, inplace = True)

# Checking for null values in train data
print(train_df.isnull().sum())

print(test_df.isnull().sum())

# spliting the categorical and numerical attributes 
df_Cat = train_df.loc[:,[x for x in train_df.columns if x in ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']]]
df_T = train_df.loc[:, 'Transported']
df_Num = train_df.loc[:,[x for x in train_df.columns if x in ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']]]

test_df_Cat = test_df.loc[:,[x for x in test_df.columns if x in ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']]]
test_df_Num = test_df.loc[:,[x for x in test_df.columns if x in ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']]]

print(isinstance(df_Cat, pd.DataFrame))
print(isinstance(df_Num, pd.DataFrame))
print(isinstance(test_df_Cat, pd.DataFrame))
print(isinstance(test_df_Num, pd.DataFrame))

# imputing the categorical attributes in most frequent strategy
from sklearn.impute import SimpleImputer
imp_Cat = SimpleImputer(strategy = "most_frequent")
df_Cat_up = imp_Cat.fit_transform(df_Cat)
test_df_Cat_up = imp_Cat.fit_transform(test_df_Cat)

# imputing the numerical attributes in mean strategy
imp_Num = SimpleImputer(strategy = 'mean')
df_Num_up = imp_Num.fit_transform(df_Num)
test_df_Num_up = imp_Num.fit_transform(test_df_Num)

print(isinstance(df_Cat_up, pd.DataFrame))
print(isinstance(df_Num, pd.DataFrame))
print(df_Cat_up[47])

# label encoding the categorical values
from sklearn.preprocessing import LabelEncoder
for i in range(len(df_Cat.columns)):
    df_Cat_up[:, i] = LabelEncoder().fit_transform(df_Cat_up[:, i])
df_T = LabelEncoder().fit_transform(df_T)
for i in range(len(test_df_Cat.columns)):
    test_df_Cat_up[:, i] = LabelEncoder().fit_transform(test_df_Cat_up[:, i])
print(df_Cat_up)
# print(test_df_Cat_up)

#Feature Scaling of numerical values
from sklearn.preprocessing import MinMaxScaler
for i in range(len(df_Num.columns)):
  df_Num_up[:, [i]] = MinMaxScaler().fit_transform(df_Num_up[:, [i]])
for i in range(len(test_df_Num.columns)):
  test_df_Num_up[:, [i]] = MinMaxScaler().fit_transform(test_df_Num_up[:, [i]])
# print(df_Num_up)
# print(test_df_Num_up)

import numpy as np
con = np.concatenate((df_Cat_up, df_Num_up), axis = 1)
test_con = np.concatenate((test_df_Cat_up, test_df_Num_up), axis = 1)
# print(con.shape)

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB  
from sklearn.ensemble import RandomForestClassifier 
from sklearn.linear_model import LinearRegression

"""# Generating submission files for Kaggle:"""

DT = DecisionTreeClassifier(criterion='entropy').fit(con, df_T)
predict_test = DT.predict(test_con)
d = {'PassengerId':test_df['PassengerId'],'Transported':[False if x==0 else True for x in predict_test]}
predict_test_df = pd.DataFrame(d)
predict_test_df.to_csv('/content/drive/MyDrive/CSE366/DT_Submission.csv', index=False)

LR = LogisticRegression().fit(con, df_T)
predict_test = LR.predict(test_con)
d = {'PassengerId':test_df['PassengerId'],'Transported':[False if x==0 else True for x in predict_test]}
predict_test_df = pd.DataFrame(d)
predict_test_df.to_csv('/content/drive/MyDrive/CSE366/LR_Submission.csv', index=False)

NB = GaussianNB().fit(con, df_T)
predict_test = NB.predict(test_con)
d = {'PassengerId':test_df['PassengerId'],'Transported':[False if x==0 else True for x in predict_test]}
predict_test_df = pd.DataFrame(d)
predict_test_df.to_csv('/content/drive/MyDrive/CSE366/NB_Submission.csv', index=False)

RF = RandomForestClassifier().fit(con, df_T)
predict_test = RF.predict(test_con)
d = {'PassengerId':test_df['PassengerId'],'Transported':[False if x==0 else True for x in predict_test]}
predict_test_df = pd.DataFrame(d)
predict_test_df.to_csv('/content/drive/MyDrive/CSE366/RF_Submission.csv', index=False)

# LR = LinearRegression().fit(con, df_T)
# predict_test = LR.predict(test_con)
# d = {'PassengerId':test_df['PassengerId'],'Transported':[False if x==0 else True for x in predict_test]}
# predict_test_df = pd.DataFrame(d)
# predict_test_df.to_csv('/content/drive/MyDrive/CSE366/LR_Submission.csv', index=False)

"""# Spliting and measuring the performance of the model"""

# train test split
from sklearn.model_selection import train_test_split
train_x, test_x, train_y, test_y = train_test_split(con, df_T, test_size = 0.3, random_state = 10)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

def measure_performance(res, predict_test , predict_train, test_y, train_y):    
    print(res)
    cm = confusion_matrix(test_y,predict_test, labels=res.classes_)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=res.classes_)
    disp.plot()
    plt.show()

    print("Accuracy Score:","%.5f" % accuracy_score(test_y, predict_test))
    print("Precision Score:","%.5f" % precision_score(test_y, predict_test))
    print("Recall Score:","%.5f" % recall_score(test_y, predict_test))
    print("F1 Score:","%.5f" % f1_score(test_y, predict_test))

DT = DecisionTreeClassifier(criterion='entropy').fit(train_x, train_y)
predict_test = DT.predict(test_x)
predict_train = DT.predict(train_x)
measure_performance(DT, predict_test, predict_train, test_y, train_y)

LR = LogisticRegression().fit(train_x, train_y)
predict_test = LR.predict(test_x)
predict_train = LR.predict(train_x)
measure_performance(LR, predict_test, predict_train, test_y, train_y)

NB = GaussianNB().fit(train_x, train_y)
predict_test = NB.predict(test_x)
predict_train = NB.predict(train_x)
measure_performance(NB, predict_test, predict_train, test_y, train_y)

RF = RandomForestClassifier().fit(train_x, train_y)
predict_test = RF.predict(test_x)
predict_train = RF.predict(train_x)
measure_performance(RF, predict_test, predict_train, test_y, train_y)